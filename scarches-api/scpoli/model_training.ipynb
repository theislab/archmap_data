{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
      "/home/alextopalova/.local/lib/python3.9/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/alextopalova/.local/lib/python3.9/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gdown\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import scarches as sca\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_kwargs = {\n",
    "    'early_stopping_metric': 'val_prototype_loss',\n",
    "    'mode': 'min',\n",
    "    'threshold': 0,\n",
    "    'patience': 20,\n",
    "    'reduce_lr': True,\n",
    "    'lr_patience': 13,\n",
    "    'lr_factor': 0.1,\n",
    "}\n",
    "\n",
    "condition_key = 'study'\n",
    "cell_type_key = ['cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('mouse_pancreas_subsample.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 17353 × 31706\n",
       "    obs: 'study_sample', 'study', 'file', 'reference', 'size_factors_sample', 'phase_cyclone', 's_cyclone', 'g2m_cyclone', 'g1_cyclone', 'sex', 'ins_score', 'ins_high', 'gcg_score', 'gcg_high', 'sst_score', 'sst_high', 'ppy_score', 'ppy_high', 'cell_filtering', 'age', 'strain', 'tissue', 'technique', 'study_sample_design', 'cell_type', 'cell_type_multiplet', 'cell_subtype', 'cell_subtype_multiplet', 'design', 'size_factors_integrated', 'pre_cell_type_unified', 'pre_cell_type_original', 'study_parsed', 'cell_type_parsed', 'low_q', 'BETA-DATA_leiden_r1.5', 'BETA-DATA_leiden_r20', 'BETA-DATA_hc_gene_programs', 'BETA-DATA_hc_gene_programs_parsed', 'BETA-DATA_leiden_r1.5_parsed', 'BETA-DATA_leiden_r1.5_parsed_const', 'CXG-DATA_n_genes', 'CXG-DATA_mt_frac', 'CXG-DATA_doublet_score', 'CXG-DATA_log10_n_counts', 'CXG-DATA_age_approxDays', 'CXG-DATA_cell_subtype_immune_reannotatedIntegrated', 'CXG-DATA_cell_subtype_endothelial_reannotatedIntegrated', 'CXG-DATA_emptyDrops_LogProb_scaled', 'CXG-DATA_diabetes_model', 'CXG-DATA_chemical_stress', 'CXG-DATA_GEO_accession', 'CXG-DATA_sex_annotation', 'cell_type_integrated_v2', 'cell_type_integrated_v2_parsed'\n",
       "    var: 'gene_symbol', 'used_integration', 'gene_symbol_original_matched', 'CXG-DATA_feature_is_filtered', 'CXG-DATA_present_Fltp_2y', 'CXG-DATA_present_Fltp_adult', 'CXG-DATA_present_Fltp_P16', 'CXG-DATA_present_NOD', 'CXG-DATA_present_NOD_elimination', 'CXG-DATA_present_spikein_drug', 'CXG-DATA_present_embryo', 'CXG-DATA_present_VSG', 'CXG-DATA_present_STZ', 'gene_symbol_FINAL'\n",
       "    uns: 'BETA-DATA_hc_gene_programs_parsed_colors', 'BETA-DATA_hc_gene_programs_parsed_order', 'BETA-DATA_leiden_r1.5_parsed_colors', 'BETA-DATA_leiden_r1.5_parsed_order', 'cell_type_integrated_v2_colors', 'cell_type_integrated_v2_parsed_order', 'field_descriptions', 'study_colors', 'study_order', 'study_parsed_colors', 'study_parsed_order'\n",
       "    obsm: 'BETA-DATA_X_umap', 'BETA-DATA_X_umap_opt', 'X_integrated', 'X_umap'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fltp_adult'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(adata.obs[condition_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without this line a TypeError is thrown\n",
    "adata.obs['cell_type'] = adata.obs['cell_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dictionary:\n",
      " \tNum conditions: 1\n",
      " \tEmbedding dim: 3\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 31706 256 3\n",
      "\tHidden Layer 1 in/out: 256 64\n",
      "\tMean/Var Layer in/out: 64 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 64 3\n",
      "\tHidden Layer 1 in/out: 64 256\n",
      "\tOutput Layer in/out:  256 31706 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scpoli_model = sca.models.scPoli(\n",
    "    adata=adata.copy(),\n",
    "    condition_key='study',\n",
    "    cell_type_keys=['cell_type'],\n",
    "    embedding_dim=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m scpoli_model\u001b[39m.\u001b[39;49mtrain( \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     n_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     pretraining_epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     early_stopping_kwargs\u001b[39m=\u001b[39;49mearly_stopping_kwargs,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     eta\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Helmholtz/archmap_data/scarches-api/scpoli/model_training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/models/scpoli/scpoli_model.py:248\u001b[0m, in \u001b[0;36mscPoli.train\u001b[0;34m(self, n_epochs, pretraining_epochs, lr, eps, reload_best, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     pretraining_epochs \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mfloor(n_epochs \u001b[39m*\u001b[39m \u001b[39m0.9\u001b[39m))\n\u001b[1;32m    238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m scPoliTrainer(\n\u001b[1;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    247\u001b[0m )\n\u001b[0;32m--> 248\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain(n_epochs, lr, eps)\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_trained_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototypes_labeled_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mprototypes_labeled\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/trainers/scpoli/trainer.py:160\u001b[0m, in \u001b[0;36mscPoliTrainer.train\u001b[0;34m(self, n_epochs, lr, eps)\u001b[0m\n\u001b[1;32m    157\u001b[0m         batch_data[key] \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Loss Calculation\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_iteration(batch_data)\n\u001b[1;32m    162\u001b[0m \u001b[39m# Validation of Model, Monitoring, Early Stopping\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_epoch_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/trainers/scpoli/trainer.py:188\u001b[0m, in \u001b[0;36mscPoliTrainer.on_iteration\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 module\u001b[39m.\u001b[39mtrack_running_stats \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m# Calculate Loss depending on Trainer/Model\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_loss \u001b[39m=\u001b[39m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(batch_data)\n\u001b[1;32m    189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    191\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/trainers/scpoli/trainer.py:392\u001b[0m, in \u001b[0;36mscPoliTrainer.loss\u001b[0;34m(self, total_batch)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, total_batch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 392\u001b[0m     latent, recon_loss, kl_loss, mmd_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtotal_batch)\n\u001b[1;32m    394\u001b[0m     \u001b[39m# Calculate classifier loss for labeled/unlabeled data\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     label_categories \u001b[39m=\u001b[39m total_batch[\u001b[39m\"\u001b[39m\u001b[39mlabeled\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/models/scpoli/scpoli.py:134\u001b[0m, in \u001b[0;36mscpoli.forward\u001b[0;34m(self, x, batch, sizefactor, celltypes, labeled)\u001b[0m\n\u001b[1;32m    132\u001b[0m     x_log \u001b[39m=\u001b[39m x\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minject_condition:\n\u001b[0;32m--> 134\u001b[0m     z1_mean, z1_log_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x_log, batch_embedding)\n\u001b[1;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     z1_mean, z1_log_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x_log, batch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/models/scpoli/scpoli.py:433\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    431\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x, batch), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFC \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFC(x)\n\u001b[1;32m    434\u001b[0m means \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_encoder(x)\n\u001b[1;32m    435\u001b[0m log_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_var_encoder(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scarches/models/scpoli/scpoli.py:623\u001b[0m, in \u001b[0;36mCondLayers.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    622\u001b[0m     expr, cond \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(x, [x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_cond, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_cond], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 623\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpr_L(expr) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcond_L(cond)\n\u001b[1;32m    624\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "scpoli_model.train( \n",
    "    n_epochs=50,\n",
    "    pretraining_epochs=40,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    eta=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scpoli_model.save('/scpoli_pancreas', overwrite =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
