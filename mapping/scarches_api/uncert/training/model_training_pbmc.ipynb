{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
      "/home/alextopalova/miniconda3/envs/archmap/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
      "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import scarches as sca\n",
    "from scarches.dataset.trvae.data_handling import remove_sparsity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=200, frameon=False)\n",
    "sc.set_figure_params(dpi=200)\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_key = 'batch' \n",
    "cell_type_key = 'final_annotation'\n",
    "target_conditions = ['Oetjen_A','Sun_sample1_CS']\n",
    "\n",
    "output = 'Immune_ALL_human.h5ad'\n",
    "\n",
    "trvae_epochs = 500\n",
    "surgery_epochs = 500\n",
    "\n",
    "early_stopping_kwargs = {\n",
    "    \"early_stopping_metric\": \"val_unweighted_loss\",\n",
    "    \"threshold\": 0,\n",
    "    \"patience\": 20,\n",
    "    \"reduce_lr\": True,\n",
    "    \"lr_patience\": 13,\n",
    "    \"lr_factor\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = sc.read(output)\n",
    "\n",
    "source_adata = adata_all[~adata_all.obs[condition_key].isin(target_conditions)].copy()\n",
    "target_adata = adata_all[adata_all.obs[condition_key].isin(target_conditions)].copy()\n",
    "source_conditions = source_adata.obs[condition_key].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_adata.write_h5ad('source__pbmc.h5ad')\n",
    "target_adata.write_h5ad('target__pbmc.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 12303 128 8\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 128 8\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 12303 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trvae = sca.models.TRVAE(\n",
    "    adata=source_adata,\n",
    "    condition_key=condition_key,\n",
    "    conditions=source_conditions,\n",
    "    hidden_layer_sizes=[128, 128],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |██------------------| 14.2%  - val_loss: 3590.7711022418 - val_recon_loss: 3545.1896972656 - val_kl_loss: 26.6363117384 - val_mmd_loss: 36.2586589482\n",
      "ADJUSTED LR\n",
      " |████----------------| 24.8%  - val_loss: 3594.2870669158 - val_recon_loss: 3539.5747282609 - val_kl_loss: 18.2229265130 - val_mmd_loss: 43.5052359208\n",
      "ADJUSTED LR\n",
      " |█████---------------| 27.8%  - val_loss: 3590.4464058254 - val_recon_loss: 3540.0509298573 - val_kl_loss: 17.3613858430 - val_mmd_loss: 38.4161085046\n",
      "ADJUSTED LR\n",
      " |██████--------------| 32.8%  - val_loss: 3593.2402237602 - val_recon_loss: 3539.5494968580 - val_kl_loss: 16.7590221737 - val_mmd_loss: 40.0321217413\n",
      "ADJUSTED LR\n",
      " |██████--------------| 34.2%  - val_loss: 3593.9598654042 - val_recon_loss: 3540.1260296365 - val_kl_loss: 16.6795218924 - val_mmd_loss: 39.6562781956\n",
      "Stopping early: no improvement of more than 0 nats in 20 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 149\n"
     ]
    }
   ],
   "source": [
    "trvae.train(\n",
    "    n_epochs=trvae_epochs,\n",
    "    alpha_epoch_anneal=200,\n",
    "    early_stopping_kwargs=early_stopping_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = 'reference_model_pbmc/'\n",
    "trvae.save(ref_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4311 × 12303\n",
      "    obs: 'batch', 'chemistry', 'data_type', 'dpt_pseudotime', 'final_annotation', 'mt_frac', 'n_counts', 'n_genes', 'sample_ID', 'size_factors', 'species', 'study', 'tissue'\n",
      "    layers: 'counts'\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 12303 128 10\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 128 10\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 12303 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_trvae = sca.models.TRVAE.load_query_data(adata=target_adata, reference_model=ref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |██████--------------| 31.6%  - val_loss: 2805.0277099609 - val_recon_loss: 2793.0004882812 - val_kl_loss: 14.7646112442 - val_mmd_loss: 0.4369621277\n",
      "ADJUSTED LR\n",
      " |██████--------------| 34.4%  - val_loss: 2818.3168334961 - val_recon_loss: 2805.2718505859 - val_kl_loss: 14.7420217991 - val_mmd_loss: 0.4404945374\n",
      "ADJUSTED LR\n",
      " |███████-------------| 37.6%  - val_loss: 2806.5301513672 - val_recon_loss: 2792.3743286133 - val_kl_loss: 14.6795158386 - val_mmd_loss: 0.4304623604\n",
      "ADJUSTED LR\n",
      " |████████------------| 41.2%  - val_loss: 2814.7688598633 - val_recon_loss: 2799.6450805664 - val_kl_loss: 14.7022061348 - val_mmd_loss: 0.4215445518\n",
      "ADJUSTED LR\n",
      " |████████------------| 42.6%  - val_loss: 2825.6467285156 - val_recon_loss: 2810.4708251953 - val_kl_loss: 14.7250926495 - val_mmd_loss: 0.4507498741\n",
      "Stopping early: no improvement of more than 0 nats in 20 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 191\n"
     ]
    }
   ],
   "source": [
    "new_trvae.train(\n",
    "    n_epochs=surgery_epochs,\n",
    "    alpha_epoch_anneal=200,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    weight_decay=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surg_path = 'surgery_model_pbmc'\n",
    "new_trvae.save(surg_path, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
